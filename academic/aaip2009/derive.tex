\documentclass[preprint]{sigplanconf}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{balance}

\include{paper}

%include paper.fmt

\newcommand{\derive}{\textsc{Derive}}

\hsdef{\begin{comment}
Show,Enum,Ord,Bounded,Serial,Arbitrary,Monoid,Binary
alpha,beta
\end{comment}}
\begin{comment}
\begin{code}
import Data.Data
import Data.Monoid hiding (First)
import Control.Parallel.Strategies

data Version
data Extension
data Compiler

class Arities a where arities :: a -> [Int]
\end{code}
\h{.hse}\begin{code}
import Language.Haskell.Exts
\end{code}
\end{comment}

\begin{document}

\conferenceinfo{3rd workshop on Approaches and Applications of Inductive Programming}{4th September 2009, Edinburgh.} %
\copyrightyear{2009} %
\copyrightdata{[to be supplied]}

\titlebanner{\today{} - \currenttime{}}        % These are ignored unless
\preprintfooter{}   % 'preprint' option specified.

\title{Deriving a DSL from One Example}
% \subtitle{}

\authorinfo{Neil Mitchell}
           {Standard Chartered, UK}
           {\verb"ndmitchell@gmail.com"}

\maketitle

\begin{abstract}
Given an appropriate domain specific language (DSL), it is possible to describe the relationship between Haskell data types and many generic functions, typically type class instances. While describing the relationship is possible, it is not always an easy task. There is an alternative -- simply give one example output for a carefully chosen input, and have the relationship derived.

When deriving a relationship from only one example, it is important that the derived relationship is the intended one. We identify general restrictions on the DSL, and on the provided example, to ensure a level of predictability. We then apply these restrictions in practice, to derive the relationship between Haskell data types and generic functions. We have used our scheme in the Derive tool, where 60\% of type classes are derived from a single example.
\end{abstract}

\category{D.3}{Software}{Programming Languages}

\terms
todo

\keywords
Haskell, todo

\section{Introduction}

In Haskell \cite{haskell}, \textit{type classes} \cite{wadler:type_classes} are used to provide similar operations for many data types. For each data type of interest, a user must define an appropriate instance. The instance definitions usually follow a highly regular pattern. One type class is the |NFData| class defined by \citet{trinder:strategies}, which reduces a value to normal form. For example, we can define a data type to describe which language a computer program is written in, and provide an |NFData| instance:

\begin{code}
data Language  =  Haskell [Extension] Compiler
               |  Whitespace
               |  Java Version

instance NFData Language where
    rnf (Haskell x_1 x_2  ) = rnf x_1 `seq` rnf x_2 `seq` ()
    rnf (Whitespace       ) = ()
    rnf (Java x_1         ) = rnf x_1 `seq` ()
\end{code}

We also need to define an |NFData| instance for the |Extension|, |Compiler| and |Version| data types. Any instance of |NFData| follows naturally from the data types structure: for each constructor, all fields have |seq| applied before, returning |()|.

Writing an |NFData| instance for one data type is simple. However, as the complexity and number of data types increases, so does the effort required. The standard solution is to express the \textit{relationship} between a data type and the instance that is associated with it. In standard tools such as DrIFT \cite{drift}, the person describing the relationship must be familiar with both the representation of a data type, and various code-generation functions. The result is that specifying an instance generator is not as straightforward as one might hope.

\begin{figure}
\begin{code}
data Sample alpha  =  First
                   |  Second  alpha alpha
                   |  Third   alpha
\end{code}
\caption{The |Sample| data type.}
\label{fig:sample}
\end{figure}

Using the techniques described in this paper, these relationships can often be automatically inferred from a single example instance. To define \textit{all} |NFData| instances, an example must be given for the |Sample| type defined in Figure \ref{fig:sample}:

\begin{code}
instance NFData a => NFData (Sample a) where
    rnf (First           ) = ()
    rnf (Second x_1 x_2  ) = rnf x_1 `seq` rnf x_2 `seq` ()
    rnf (Third x_1       ) = rnf x_1 `seq` ()
\end{code}

The |NFData| instance for |Sample| follows the same pattern as for |Language|. From this single example, we can infer the relationship. However, there are many relationships between the data type and the result -- for example the function might always produce the instance for |Sample|, regardless of the input type. To overcome this problem, we require that the relationship be written in a domain specific language (DSL), and by imposing certain restrictions, we can ensure that any generated relationship is indeed correct.

\subsection{Contributions}

This paper makes the following contributions:

\begin{itemize}
\item We describe a scheme which allows us to infer predictable and correct relationships. \ref?
\item We describe how this scheme is applicable to instance generation. \ref?
\item We outline a method for guessing values in our DSL, without resorting to unguided search. \ref?
\item We give measured results, including reasons why our inference fails \ref?. In our experience, over 60\% of Haskell class instances can be determined using this technique.
\end{itemize}

\section{Our Derivation Scheme}

In this section we seek to define a general derivation scheme, relating inputs to outputs, which we can use in our specific example of class instance generation. In general terms, a function takes an input to an output. In our case, we restrict functions to only those that can be described by a DSL. Our scheme can be implemented in Haskell as follows:

\h{.short}\begin{code}
data Input
data Output
data DSL

apply :: Input -> DSL -> Output
\end{code}

The |apply| function takes an |Input|, and a |DSL| (representing a function), and generates an |Output|.

Now let's move on and look at our derivation scheme. Given a single result, of the |Output| type, for a particular |Input| sample, we want to guess a particular DSL.

\begin{code}
sample :: Input
guess :: Output -> [DSL]
\end{code}


Here |sample| is whatever sample needs to be generated. The |guess| function generates a (possibly empty) set of DSL's. Given these DSL's, we want to determine what is necessary for them to be correct, and to be predictable.

\subsection{Correctness}

A guess is correct iff:

\ignore\begin{code}
-- guess is correct
forall o `elem` guess output `o` apply input o == output
\end{code}

Given that |guess| requires correctness, it is easy to write a helper. Now |guess'| can be written without regard to correctness.

\begin{code}
guess x = [y | y <- guess' x, apply input y == output]
\end{code}

\subsection{Predictability}

\ignore\begin{code}
-- equivalence of DSL terms
d_1 ~== d_2 = forall i `elem` Input `o` apply i d_1 == apply i d_2

-- predictability
forall d_1, d_2 `elem` DSL `o` apply input d_1 == apply input d_2 => d_1 ~== d_2
\end{code}

We define two DSL's to be similar \todo{better word} |(~==)|, if for all possible inputs they will produce results which are equivalent. In a similar way we can classify two functions as equal if for all possible input/output pairs they are the same.

The predictability lemma requires that if a DSL successfully guesses the input/output pair, it must be equivalent to all other possible DSL. Note that the predictability lemma does not mention |guess|, although it may require a specially chosen |input| value.

By combining the predictability lemma with the correctness lemma, we can guarantee that if |guess| returns any results, any result is equally good to any other. This frees |guess| from any burden. Combined with defining |guess| in terms of |guess'| allows us to write any terminating expression for |guess| and still get correct behaviour.

\section{Concretely}

In this section we map the abstract aspects from the previous section into concrete things in our instance generation scheme.

\subsection{Output}

Our output language is the language of Haskell declarations. Because of the tool we're writing, we don't have a choice about the output domain. Internally we use haskell-src-exts, but that has a big tree. To simplify things we use a universal data type, we translate to and from haskell-src-exts \ref?.

\begin{code}
data Output = OString String
            | OInt Int
            | OList [Output]
            | OApp String [Output]
\end{code}

\subsection{Input}

We have more freedom over input. We choose which information to present in a data type, for example we can choose to make the derivation depend on the module name, or not. We choose not too, however this does eliminate some derivations \ref{typeable}. In \ref{extensions} we describe how you could beef up the power.

Our |Input| language is that of algebraically constructed Haskell data types:

\begin{code}
data Input = Input {dataName :: String, dataVars :: Int, dataCtors :: [Ctor]}
data Ctor = Ctor {ctorName :: String, ctorIndex :: Int, ctorArity :: Int}
\end{code}

Note the details we choose to represent and the details we abstract away. For example, we allow derivations to depend on the arity or index of a constructor, but not the types of the constructors arguments.

\subsection{DSL}

The DSL we have most freedom over. We construct the DSL from a number of parts.

\subsubsection{Constants}

One useful thing is to represent is constants, so we can lift the |Output| type in to |DSL|.

\begin{figure}
\begin{code}
data DSL
    -- Constants
    = String String
    | Int Int
    | List [DSL]
    | App String DSL
    -- Operations
    | Concat DSL
    | ShowInt DSL
    | Reverse DSL
    -- Fold
    | Fold DSL DSL
    | Head
    | Tail
    -- Constructors
    | CtorIndex
    | CtorArity
    | CtorName
    | MapCtor DSL
    -- Fields
    | MapField DSL
    | FieldInd
    -- Custom
    | Instance [String] String DSL{-[InstDecl]-}
    | DataName
    | Application DSL{-List-}
\end{code}
\caption{DSL data type}
\end{figure}

We decide that if the DSL inside |App| doesn't evaluate to a List, then it's wrong.

\subsubsection{Operations}

The DSL inside |Concat| must evaluate to a list of list or a list of string. The DSL inside |ShowInt| must evaluate to an Int. Reverse must operate over a list.

These operations are fairly general.

\subsubsection{Fold}

Describe the fold here.

\subsubsection{Constructors}

We also want to talk about constructors:

\subsubsection{Fields}

These are generalisations of things which aren't otherwise inferable.



\subsection{Restrictions for predictability}

You can only refer to the arity of something if you also refer to it's constructor name. Every |MapCtor| must contain a |CtorName| somewhere within it. You can't have a constructor name as a constant. Consider:

\begin{code}
instance Arities (Sample alpha) where
    arities _ = [0,2,1]
\end{code}

However, it's easy to write:

\begin{code}
instance Arities (Sample alpha) where
    arities _ = [0 `const` First{}, 2 `const` Second{}, 1 `const` Third{}]
\end{code}

You can't have a string ended in either Sample or a constructor name, without it being either |DataName| or |CtorName|.
With these restrictions you do indeed have the property that each input/output pair ensures a unique DSL. This explains why it's important that the arities and indexes are not the same for all items, i.e. why |Second| doesn't take 1 argument and |Third| takes 2.

\section{Implementing |guess|}

Since we know that all answers are just as good as each other (predictability), and that given the restrictions listed in ?, if the answer is correct then they must all be correct, the guess function only needs to be a best attempt. This makes the guess function much easier to see.

\begin{code}
data Guess = Guess DSL
           | GuessInt Int (DSL -> DSL)
           | GuessCtr Int Bool DSL  -- 0 based index, does it mention CtorName
\end{code}

The only hard thing to guess are lists. The idea of a list is that all elements must have the same |Guess| framework. We can promote |Guess| to any of the others. We do the guessing of lists by first guessing different ones, then guessing similar ones.

\section{Implementation Details}

SYB stuff goes in here. Haskell-src-exts.

We skip src loc in haskell-src-exts, as it's irrelevant.

Post-generation optimisation tweaks. i.e. \ignore|a && True => a|. Could perhaps use HLint in a future version.

\h{.hse}\begin{code}
simplify :: Biplate alpha Exp => alpha -> alpha
simplify = transformBi fExp
    where
        x ~= y = prettyPrint x == y

        fExp (App op (List xs))
            | op ~= "length" = Lit $ Int $ fromIntegral $ length xs
            | op ~= "head" = head xs
        fExp (InfixApp (Lit (Int i)) op (Lit (Int j)))
            | op ~= "-" = Lit $ Int $ i - j
            | op ~= ">" = Con $ UnQual $ Ident $ show $ i > j
        fExp (InfixApp x op y) | op ~= "`const`" = x
        fExp (App (App con x) y) | con ~= "const" = x
        fExp (Paren (Var x)) = Var x
        fExp (Paren (Lit x)) = Lit x
        fExp x = x
\end{code}

\section{Results}

Inference time to write the derivations for everything to a file is under a tenth of a second. To write the data to the screen takes 3 tenths of a second. We conclude that guesses aren't too slow!

\subsection{Limitations of Automatic Derivation}
\label{sec:automatic_failure}

The instance generation scheme given is not complete -- there exist instances whose generator cannot be determined. The Derive tool \cite{derive} is a program for generating instances for user defined data types. Of the 24 instances supported by the Derive tool, 15 are expressed by example, while 9 require manually written instance generators. There are several reasons some instances cannot be determined:

\begin{description}

\item[Non-inductive definitions:] For example, the |Binary| class serialises a value to disk. For each value, a tag is written to indicate the constructor. If a data type has only one constructor, the tag is omitted. These instances are not inductive -- the single constructor does not follow the same pattern.

\item[Type-based definitions:] For example, the |Monoid| class requires items of the same type to be processed using |mappend|, but items of a different type use |mempty|. Automatic derivation has no notion of type-specific behaviour.

\item [Record-based definitions:] Haskell provides records, which allow fields to be labelled. The |Show| class outputs the field name if present, but the examples have no notion of label-specific behaviour. By extending |Sample|, record definitions could be determined, but this change would increase the complexity of all other example instances.

\end{description}

\subsection{Generation of Standard Classes}
\label{sec:automatic_success}

Many instance generators can be expressed by example -- including some from the standard Haskell libraries (|Enum|, |Ord|, |Bounded|) and publicly distributed libraries (|Serial|, |Arbitrary|). The |Data| class was introduced in Scrap Your Boilerplate \cite{lammel:syb}, and allows Haskell programmers to write concise queries and transformations. The fundamental operation is |gfoldl|, which involves a fold over each value, and the application of an argument to join the fields. An example instance can be given as:

\begin{code}
instance Data alpha => Data (Sample alpha) where
    gfoldl k r (First            ) = r First
    gfoldl k r (Second  x_1 x_2  ) = r Second  `k` x_1 `k` x_2
    gfoldl k r (Third   x_1      ) = r Third   `k` x_1
\end{code}

\noindent The generator function is inferred as:

\ignore\begin{code}
instance Data \? <| dataname |> where
    <| MAP ctors (
        gfoldl k r
            (<| ctorname |> \? <| MAP [1..ctorarity] (x <| # |> ) |> ) =
            <| FOLDR k (r \? <| ctorname |>)
                <| MAP [1 .. ctorarity] (x <| # |> ) |>
            |>
    ) |>
\end{code}

\subsection{Extensions}

How would we increase it to get more power.

\section{Related Work}
\label{sec:related}

The purpose of this work is to find a pattern, and generalise that pattern to other situations. Genetic algorithms \cite{genetic_algorithms} are often used to automatically find a pattern in a data set. Genetic algorithms work by evolving a hypothesis (a gene sequence) and testing on a sample problem. They are well suited to search problems where the utility function is continuous -- close hypotheses have similar fitness. The main difference from this paper is that the hypothesis is random, whereas ours is strongly directed by the shape of the example.

The area of optical character recognition \cite{ocr} has some similar characteristics -- a page is analysed to look for common patterns (pictures or text passages), which can be processed further. This is related to the process of using the fold pattern (\S\ref{sec:fold}), where a repeating pattern is detected. The difference is that character recognition works on image data, which does not have the same precision as program code.

The closest work we are aware of is that of the theorem proving community. Induction is a very common tactic for writing proofs, and well supported in systems such as HOL Light \cite{hol_light}. Typically the user must suggest the use of induction, which the system checks for validity. Automatic inference of an induction argument has been tried \cite{mintchev:reasoning}, but is rarely successful.

The concepts in this paper are applicable outside the domain of instances in Haskell. Any programming language operation that exhibits some degree of uniformity could be automated. To give one example: the object-orientated community have embraced design patterns \cite{design_patterns}, which involve many recurring patterns.

\section{Conclusions and Future Work}
\label{sec:conclusion}

We have presented a mechanism for automatically deriving instance generators for Haskell type classes. Our technique has been implemented in the Derive tool \cite{derive}, where 60\% of instance generators are specified by example. The ease of creating new instances has enabled several users to contribute instance generators to the Derive tool. We see several lines of future work:

\begin{itemize}
\item Using automatic instance generation allows the underlying tool to change the API for specifying instances, without requiring human intervention to modify the generators -- they can simply be regenerated. This freedom allows instances to be expressed in new ways. Currently an instance is a fragment of compile time code, but using Haskell's reflection capabilities \cite{lammel:syb2}, instances could be derived at run-time, removing the inconvenience of a separate preprocessor.
\item The provided data type (Figure \ref{fig:dataname}) allows many instances to be inferred -- but more would be desirable. One approach to specifying more instances would be to augment the existing data type with additional features, such as record names (see \S\ref{sec:automatic_failure}). An alternative approach would be to introduce new data types with features specifically targeted for certain types of definition. Care would have to be taken to ensure that these extensions do not substantially increase the complexity of writing examples.
\item We could make everything more type safe using GADT's.
\end{itemize}

Computers are ideally suited to applying repetitive patterns, but specifying these patterns can be complex and error prone. By specifying the result, instead of the pattern, a user can focus on what they want, rather than the mechanism by which this is realized.


\subsection*{Acknowledgements}

Thanks to Stefan O'Rear help with the \derive{} tool.


\balance

\bibliographystyle{plainnat}
\bibliography

\end{document}
