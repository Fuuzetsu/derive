\documentclass[preprint]{sigplanconf}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{balance}

\include{paper}

%include paper.fmt

\newcommand{\derive}{\textsc{Derive}}

\hsdef{\begin{comment}
Show,Enum,Ord,Bounded,Serial,Arbitrary,Monoid,Binary
alpha,beta
\end{comment}}
\begin{comment}
\begin{code}
import Data.Data
import Data.Monoid hiding (First)
import Control.Parallel.Strategies

data Version
data Extension
data Compiler

class Arities a where arities :: a -> [Int]
\end{code}
\h{.hse}\begin{code}
import Language.Haskell.Exts
\end{code}
\end{comment}

\begin{document}

\conferenceinfo{3rd workshop on Approaches and Applications of Inductive Programming}{4th September 2009, Edinburgh.} %
\copyrightyear{2009} %
\copyrightdata{[to be supplied]}

\titlebanner{\today{} - \currenttime{}}        % These are ignored unless
\preprintfooter{}   % 'preprint' option specified.

\title{Deriving a DSL from One Example}
% \subtitle{}

\authorinfo{Neil Mitchell}
           {Standard Chartered, UK}
           {\verb"ndmitchell@gmail.com"}

\maketitle

\begin{abstract}
Given an appropriate domain specific language (DSL), it is possible to describe the relationship between Haskell data types and many generic functions, typically type class instances. While describing the relationship is possible, it is not always an easy task. There is an alternative -- simply give one example output for a carefully chosen input, and have the relationship derived.

When deriving a relationship from only one example, it is important that the derived relationship is the intended one. We identify general restrictions on the DSL, and on the provided example, to ensure a level of predictability. We then apply these restrictions in practice, to derive the relationship between Haskell data types and generic functions. We have used our scheme in the Derive tool, where 60\% of type classes are derived from a single example.
\end{abstract}

\category{D.3}{Software}{Programming Languages}

\terms
todo

\keywords
Haskell, todo

\section{Introduction}
\label{sec:introduction}

In Haskell \cite{haskell}, \textit{type classes} \cite{wadler:type_classes} are used to provide similar operations for many data types. For each data type of interest, a user must define an appropriate instance. The instance definitions usually follow a highly regular pattern. Many libraries define new type classes, for example \citet{trinder:strategies} define the |NFData| type class, which reduces a value to normal form. As an example, we can define a data type to describe which language a computer program is written in, and provide an |NFData| instance:

\begin{code}
data Language  =  Haskell [Extension] Compiler
               |  Whitespace
               |  Java Version

instance NFData Language where
    rnf (Haskell x_1 x_2  ) = rnf x_1 `seq` rnf x_2 `seq` ()
    rnf (Whitespace       ) = ()
    rnf (Java x_1         ) = rnf x_1 `seq` ()
\end{code}

We also need to define |NFData| instances for the data types |Extension|, |Compiler| and |Version|. Any instance of |NFData| follows naturally from the structure of a data type: for each constructor, all fields have |seq| applied before, returning |()|.

Writing an |NFData| instance for one data type is simple -- but the effort required increases as the data types get more complex and numerous. The standard solution is to express the \textit{relationship} between a data type and associated instance. In standard tools such as DrIFT \cite{drift}, the person describing the relationship must be familiar with both the representation of a data type, and various code-generation functions. The result is that specifying the relationship is not as straightforward as one might hope.

\begin{figure}
\begin{code}
data Sample alpha  =  First
                   |  Second  alpha alpha
                   |  Third   alpha
\end{code}
\caption{The |Sample| data type.}
\label{fig:sample}
\end{figure}

Using the techniques described in this paper, these relationships can often be automatically inferred from a single example. To define the relationship for \textit{all} |NFData| instances, we require an example to be given for the |Sample| data type defined in Figure \ref{fig:sample}:

\begin{code}
instance NFData alpha => NFData (Sample alpha) where
    rnf (First           ) = ()
    rnf (Second x_1 x_2  ) = rnf x_1 `seq` rnf x_2 `seq` ()
    rnf (Third x_1       ) = rnf x_1 `seq` ()
\end{code}

The |NFData| instance for |Sample| follows the same pattern as for |Language|. From this single example, we can infer the relationship. However, there are many possible relationships between the data type and the result -- for example the function might always generate the instance for |Sample|, regardless of the input type. We overcome this problem by requiring that the relationship be written in a domain specific language (DSL), and that the example has certain properties (see \S\ref{sec:scheme}). With our restrictions, we can regain predictability.

\subsection{Contributions}

This paper makes the following contributions:

\begin{itemize}
\item We describe a scheme which allows us to infer predictable and correct relationships (\S\ref{sec:scheme}).
\item We describe how this scheme is applicable to instance generation, both in a high-level manner (\S\ref{sec:instances}), and more detailed practical concerns (\S\ref{sec:implementation}).
\item We outline a method for deriving function in our DSL, without resorting to unguided search (\S\ref{sec:guess}).
\item We give measured results (\S\ref{sec:results}), including reasons why our inference fails (\S\ref{sec:failures}). In our experience, over 60\% of Haskell class instances can be determined using this technique.
\end{itemize}

\section{Our Derivation Scheme}
\label{sec:scheme}

In this section we define a general derivation scheme, relating inputs to outputs, which we can later use in our specific example of type class instance derivation. In general terms, a function takes an input to an output. In our case, we restrict functions to only those that can be described by a DSL. Therefore, we need a function to serve as an interpreter for our DSL (which we call |apply|), which takes an input and a DSL and produces an output. Our scheme can be implemented in Haskell as follows:

\h{.short}\begin{code}
data Input
data Output
data DSL

apply :: DSL -> Input -> Output
\end{code}

Now we consider our derivation scheme. Given a single result of the |Output| type, for a particular |Input| sample, we want to derive a particular DSL. However, we may not always be able to derive an appropriate DSL, so our derivation function must allow the possibility of failure. Instead of maybe producing a single DSL result, we instead choose to produce a list of DSL results, following the lead of \citet{wadler:list_of_successes}. Once again, we can implement this in Haskell as:

\begin{code}
sample :: Input
derive :: Output -> [DSL]
\end{code}

We require our scheme to have two particular properties -- correctness (it works) and predictability (its what the user intended). We now define each of these properties more formally, along with the necessary restrictions to achieve them in general.

\subsection{Correctness}

A guess is correct if all derived DSL's, when applied to the sample input, produce the given output:

\ignore\begin{code}
forall d `elem` derive output `o` apply d sample == output
\end{code}

Given an arbitrary |derive'| function, which does not necessarily ensure correctness, it is easy to write a wrapper which is guaranteed correct, by simply filtering out the incorrect DSL's. By using a wrapper, we can remove some constraints from the |derive'| function -- either simplifying the implementation, or gaining a higher assurance of correctness.

\begin{code}
derive x = [y | y <- derive' x, apply y sample == output]
\end{code}

\subsection{Predictability}

We define two DSL's to be congruent |(~==)|, if for each input they both produce the same result -- i.e. |apply d_1 == apply d_2|.

\ignore\begin{code}
d_1 ~== d_2 = forall i `elem` Input `o` apply d_1 i == apply d_2 i
\end{code}

Our |derive| function returns a list of possible DSL's. In order to ensure predictability, it is important that all the possible DSL's are congruent -- meaning that we can pick any as the DSL denoting the relationship.

\ignore\begin{code}
forall d_1,d_2 `elem` derive output `o` d_1 ~== d_2
\end{code}

Unfortunately, this property is very dependent on the |derive| function. Given two different implementations of |derive|, which produce different (but still correct) relationships for a particular example, the user would have lost predictability. Therefore, we require a stronger property to ensure predictability. Not only must all results from |derive| be congruent, but all results satisfying the correctness property must be congruent:

\ignore\begin{code}
forall d_1, d_2 `elem` DSL `o` apply d_1 sample == apply d_2 sample => d_1 ~== d_2
\end{code}

It is important that the predictability lemma does require any conditions on |derive|, although it may require a specially chosen |sample| value. To prove the predictability property does not require knowledge of the |derive| function, and can be proven given a particular DSL and sample value.

\subsection{Summary}

If the predictability property holds for the DSL and sample value, and we use the modified |derive| in terms of |derive'|, then any result produced by |derive| will be a valid relationship. These properties allow us to write the |derive| function without regard to correctness, focusing on other attributed (which we discuss in \S\ref{sec:guess}).

To use this general scheme, we need to instantiate it to our particular problem (\S\ref{sec:instances}), prove the predictability property (\S\ref{sec:predictability}), and implement a |derive| function (\S\ref{sec:guess}).

\section{Deriving Instances}
\label{sec:instances}

In this section we apply the scheme from the previous section to the problem of deriving type class instances. We let the output type be Haskell source code and the input type by a representation of algebraic data types. The DSL contains features such as list manipulation, constant values, folds and maps. We first describe each type in detail, then discuss the restrictions necessary to satisfy the predictability property.

\subsection{Output}

We wish to allow generation of any sequence of Haskell declarations, where a declaration is typically a function definition or type class instance. There are several options for how to represent the type of a sequence of declarations:

\begin{itemize}
\item[String] A sequence of Haskell declarations can be represented as a string, however this lack of structure has several disadvantages. It is easy when constructing strings to generate invalid programs, the indentation and layout of Haskell are hard to generate in a compositional way and it is hard to recover structure that is likely to be useful for deriving relationships.
\item[Pretty printing combinators] Some tools such as DrIFT \cite{drift} generate Haskell code using pretty printing combinators. These combinators supply more structure than strings, but the structure is linked to the presentation, rather than the meaning of constructs.
\item[Typed abstract syntax tree (AST)] The standard way of working with Haskell source code is using a typed AST -- an AST where different types of fragment (i.e. declarations, expressions and patterns) are restricted to different positions in the tree. The first version of \derive{} used a typed AST, specifically Template Haskell \cite{template_haskell}. This approach preserves all the structure, and makes it reasonably easy to ensure the generated program is syntactically valid. By combining a typed AST with a parser and pretty printer we can convert to strings where necessary.
\item[Untyped abstract syntax tree (AST)] An untyped AST is one where all fragments have the same type, and the types do not restrict where they may occur. The removal of types increases the number of invalid programs that can be written -- for example a pattern could occur when a declaration was expected. However, by removing the types we increase the uniformity of the tree, in turn simplifying operations that wish to operate on the tree in a uniform manner.
\end{itemize}

For our purposes, it is clear that both string and pretty printing combinators are unsuitable -- they lack sufficient structure to implement the |derive| operation. The use of a typed AST made some things harder, using a typed AST meant that some operations had to be duplicated for each type of interest -- which for Template Haskell means 26 separate data types. Many of the operations were complicated by the introduction of a type, in particular it requires the DSL to track the output type, and propagate type information through the |derive| function. For that purpose we decided to usee an untyped AST. We choose universal, but suspect you could acheive the same thing with GADT's and a typed abstract syntax tree. Unfortunately this type information would propagate though everywhere, resulting in lots of complication. To generate an untyped AST it makes sense to start from an existing typed AST and translate.

The use of Template Haskell gave a number of advantages -- it is built in to GHC and can represent a large range of Haskell programs. In addition, being tied to Template Haskell was not the advantage we had originally hoped, it's reasonably complex and changes with GHC version. The use of Template Haskell also had other disadvantages, it is tightly integrated in to GHC which makes it difficult to change, and as it is tightly integrated to GHC it tends to evolve at a slower rate. It doesn't support as many language extensions. It has a difficult to work with API, especially the |Q| monad. It's difficult to separate from GHC, to run as a standalone program.

We instead decided to use haskell-src-exts \cite{haskell_src_exts}, which is a big tree. We then translate it to a universal data type, as described in \S\ref{sec:universe}. Concretely, our universal data type is:

\begin{code}
data Output  =  OString String
             |  OInt Integer
             |  OList [Output]
             |  OApp String [Output]
\end{code}

Here |OString| and |OInt| represent concrete terminals. The |OList| constructor generates a list from a sequence of  |Output| values. The most interesting constructor is |OApp|, which constructs a value in the resultant typed tree. For example |Just [1]| would be represented as |OApp "Just" [OList [OInt 1]]|.

\subsection{Input}

While the output type is largely dictated by the necessity to generate Haskell, we have much more freedom over the input type. The input type represents Haskell data types, but we can choose which details to provide, which in turn impacts on which possible relationships we can represent. For example, we can choose to include the module name in which the data is defined in, or we can choose to omit this detail. We choose not too, however this does eliminate some derivations, for example the |Typeable| type class \cite{syb1}.

For our |Input| type we use that of algebraically constructed Haskell data types. We include details such as the airty of constructors, and the number of type variants, but omit details such as types and record field names. Our |Input| type is:

\begin{code}
data Input = Input {dataName :: String, dataVars :: Integer, dataCtors :: [Ctor]}
data Ctor = Ctor {ctorName :: String, ctorIndex :: Integer, ctorArity :: Integer}
\end{code}

And values corresponding to the |Sample| data type from Figure \ref{fig:sample}, and the |Language| data type from \S\ref{sec:introduction}.

\begin{code}
languageType :: Input
languageType = Input "Language" 0
    [Ctor "Haskell" 0 2
    ,Ctor "Whitespace" 1 0
    ,Ctor "Java" 2 1]

sampleType :: Input
sampleType = Input "Sample" 1
    [Ctor "First" 0 0
    ,Ctor "Second" 1 2
    ,Ctor "Third" 2 1]
\end{code}

The |Input| constructor records the name of the data type, and the number of type variables the data type takes. For each constructor we record it's name, the 0-based index of the type, and the arity of the constructor. For example, we allow derivations to depend on the arity or index of a constructor, but not the types of the constructors arguments. In \S\ref{extensions} we describe phow you could beef up the power.

\subsection{DSL}

\begin{figure}
\begin{code}
data DSL
    -- Constants
    = String String
    | Int Integer
    | List [DSL]
    | App String DSL{-[alpha]-}
    -- Operations
    | Concat DSL{-[[alpha]]-}
    | ShowInt DSL{-Int-}
    | Reverse DSL{-[alpha]-}
    -- Fold
    | Fold DSL DSL
    | Head
    | Tail
    -- Constructors
    | MapCtor DSL
    | CtorIndex
    | CtorArity
    | CtorName
    -- Fields
    | MapField DSL
    | FieldInd
    -- Custom
    | DataName
    | Application DSL{-[Exp]-}
    | Instance [String] String DSL{-[InstDecl]-}
\end{code}
\caption{DSL data type}
\label{fig:dsl}
\end{figure}

The type we have most freedom over is the DSL, and we present our DSL type in \ref{fig:dsl}. We have divided the DSL in to sections, which we present separately. Each constructor has an interpretation, and a set of circumstances in which it is valid to occur. Our DSL evaluates in to an |Output| type, so we can view the semantics through the |apply| function. The complete |apply| function is given in Appendix \ref{sec:apply}.

It would be possible to encode many of the invariants if we used a DSL represented as a GADT \cite{GADT}. However, for simplicity we choose not to.

\subsubsection{Constants}

It is useful to represent is constants, so we can lift the |Output| type in to |DSL|. The |String|, |Int|, |List| and |App| constructors are equivalent to the |Output| variants, with the exception of |App|. Instead of |App| a list of arguments, similarly to |OApp|, we take a single |DSL|. We do require the |DSL| to evaluate to a list, which is used as the list of arguments. We consider a violation of this to be an error.

\subsubsection{Operations}

We provide a limited set of operations that operate on types. The argument to |Concat| must evaluate to either a list of lists, or a list of strings, which are then concatentated. The |ShowInt| argument must be an |Int|, which is then shown to be a |String|. The |Reverse| operation reverses a list. All these operations are relatively simple, and could be appropriate to many DSL's. Note that we do not provide an append or |(++)| operation, however one can be created from |List| and |Concat|.

\subsubsection{Fold}

The |Fold| operation can implement either a |foldr1| or |foldl1|. The first argument to the |Fold| constructor is the function -- a DSL operation contains both |Head| and |Tail| constructors. The second argument must evaluate to a list that has at least one element. If the list has exactly one element, then that is the result. If there is more than one result, then the |Head| is replaced with the first element, and the |Tail| is replaced with the fold over the remaining elements. This can be described by:

\ignore\begin{code}
Fold fn [x]) = x
Fold fn (x:xs)) = fn[x / Head, Fold fn xs / Tail]
\end{code}

For example, to implement the |concat| fold in terms of an |Append| constructor would be |Fold (Append Head Tail)|. Of course, in contrast to the provided |Concat|, this would crash if there were no elements in the list. The fold operation is more complicated than the others, but a general operation not specific to our problem, and is certainly useful.

\subsubsection{Constructors}

To insert information from constructors we provide a |MapCtor| operation. This operation generates a list, with one copy of the DSL for each constructor. Within the operation for |MapCtor| we allow the |CtorIndex|, |CtorArity| and |CtorName| constructors, which correspond to the information contained within each constructor -- if these operations are encountered elsewhere they are an error. They all produce an integer value.

\subsubsection{Fields}

The |MapField| operation is similar to |MapCtor|, it maps over each field within a constructor. The operation is only valid within a |MapCtor|. Within a |MapField|, the |FieldInd| operation returns the 1-based index. While most things in Haskell are 0-based, it actually seemed more natural to use 1-based, as they usually correspond to indexes on variables.

\subsubsection{Custom}

The final operations are all very specific to our particular problem, and each encode specific situations which are problematic. The first is |DataName|, which returns the string corresponding to the name of the data type. The haskell-src-exts library has binary application, where multiple applications are often chained. Sometimes it is useful to have a vector application operation, which we construct with the |Application| operation.

The last operation is |Instance|, and is quite specific to our problem. For many data types, there is a very specific pattern for instance definitions. For example, given the type |Either alpha beta|, a typical instantiation might be:

\begin{code}
instance (Show alpha, Ord alpha, Show beta, Ord beta) => ShowOrd (Either alpha beta) where
    ...
\end{code}

This pattern can be abstracted by saying what context is required for each type variable (i.e. |Show| and |Ord| in this example), what the main class is (i.e. |ShowOrd|), and a DSL to generate the body -- which we do with the |Instance| operation. If we were to attempt to infer this pattern without a specific |Instance| operation, we would need to be able to operate over the type variables of a data type, which would almost always result in this particular type.

\subsection{Restrictions for predictability}
\label{sec:predictability}

In order to ensure predictability there must be no non-congruent DSL values which give equal results when applied to the sample input. However, currently this not true. Consider the simple counterexample of |DataName| vs |String "Sample"|. When applied to the sample input, both will generate |OString "Sample"|, but when applied to another data  type they will generate different values. To regain predictability we impose two additional invariants on the |DSL|:

\begin{enumerate}
\item The strings |Sample|, |First|, |Second| and |Third| cannot be the suffix of any |String| operation. In the above example, the DSL |String "Sample"| would therefore be invalid.
\item Within |MapCtor| we require that the contained DSL \textit{must} include a |CtorName|.
\end{enumerate}

We have already seen an example of the first restriction in practice, now let us examine the second. Let us consider a practical example, consider:

\begin{code}
instance Arities (Sample alpha) where
    arities _ = [0,2,1]
\end{code}

This could either infer that the |arities| function always returns |[0,2,1]|, or perhaps the arities function returns the arities of each successive constructor. While it is easy as humans to infer the intention, there is a potential ambiguity. Using the second restriction, we conclude that this must always represent the constant operation. Of course, if we want to write a correct |arities| operation, it is easy to write:

\begin{code}
instance Arities (Sample alpha) where
    arities _ = [0 `const` First{}, 2 `const` Second{}, 1 `const` Third{}]
\end{code}

This code may seem less efficient, but any good program optimiser would certainly generate identical code. We return to the issue of simplification in \S\ref{sec:simplify}. Given that no constructor names may occur in |String| operations, and that |CtorName| must occur within every |MapCtor|, we can be sure that all constructor patterns are appropriately parameterised. The only other possible source of ambiguity is if two items could be generated within a constructor with the same value -- for example if all indexes and arities in the sample data type were equal. However, we have avoided this particular problem by ensuring that |Second| has index 1 has arity 2, while |Third| has the opposite.

\section{Deriving Instances}
\label{sec:guess}

This section covers the implementation of the |derive| function, as described in \ref{sec:scheme}. We believe the scheme we produce always generates correct DSL's, but it is unnecessary to prove this property (see \S\ref{sec:correctness}). We have also shown that our DSL and sample input guarantee predictability without regard to the |derive| function, provided we don't generate DSL's violating the restrictions outlined in \S\ref{sec:predictability}.

Given that we don't need to worry about predictability and correctness, we can focus on other issues. Naturally, we want the |derive| function to terminate, and ideally terminate within a reasonable time bound. But the main issue is that we desire that if there is a possible derivation, that the scheme find it. Namely:

\begin{code}
forall o `elem` Output, d `elem` DSL `o` null (derive o) => apply d sample /= o
\end{code}

We are unaware of a |derive| implementation that meets such a property. However, we aim to come as close as we can, i.e. to have the property be true for as many output values as possible.

There are many possible approaches for structuring a |derive| function, and we hope that the scheme we have described provides ample opportunity for experimentation. We have structure our particular scheme around the the notion of a parameterised guess. The central idea is that each fragment of output is related to a guess -- a DSL parameterised by some aspect, i.e. within a |MapCtor| the guesses will be parameterised by a constructor. We then infer a list of guesses, starting at the leaf nodes and working up. When we attempt to generalise over all constructors, say to generate a |MapCtor|, we check that one of the guesses is suitable for all items, and then lift that guess from a guess parameterised by constructor, to one parameterised by nothing. Our central |Guess| type is:

\begin{code}
data Guess  =  Guess DSL
            |  GuessCtr Int Bool DSL
            |  GuessInt Int (DSL -> DSL)

derive :: Output -> [DSL]
derive o = [d | Guess d <- guess o]

guess :: Output -> [Guess]
\end{code}

The |Guess| constructor represents a guess that is not parameterised by a constructor or field name, i.e. does not necessarily come below a |MapCtor| or |MapField|. Another way of viewing it is that a |Guess| is parameterised by the entire data type. A |GuessCtr| is paramterised by a constructor, where the first field is the 0-based index of the constructor, and the second field is a boolean which is |True| if the associate DSL contains |CtorName|, and |False| if it does not. The final constructor, |GuessInt i f| is a guess parameterised by an integer, where applying |f (Int i)| results in an appropriate DSL. A |GuessInt| can become either a constant, a |GuessCtr| where the integer is derived from either the arity or index, or a |MapField|.

Since we start at the bottom and guess upwards, we consider each guess type individually. They are then composed.

\subsection{Constants}

These are relatively easy. Strings and Int's.

\subsection{Custom values}

These are just specific checks.

\subsection{Lists}

The only hard thing to guess are lists. The idea of a list is that all elements must have the same |Guess| framework. We can promote |Guess| to any of the others. We do the guessing of lists by first guessing different ones, then guessing similar ones.

\subsection{Folds}


\section{Implementation Details}
\label{sec:implementation}

\subsection{Typed AST to Untyped AST}s
\label{sec:universe}

SYB stuff goes in here. Haskell-src-exts.

We skip src loc in haskell-src-exts, as it's irrelevant.

\subsection{DSL Optimisation}

\subsection{Output Optimisation}
\label{sec:simplify}

Post-generation optimisation tweaks. i.e. \ignore|a && True => a|. Could perhaps use HLint in a future version.

\h{.hse}\begin{code}
simplify :: Biplate alpha Exp => alpha -> alpha
simplify = transformBi fExp
    where
        x ~= y = prettyPrint x == y

        fExp (App op (List xs))
            | op ~= "length" = Lit $ Int $ fromIntegral $ length xs
            | op ~= "head" = head xs
        fExp (InfixApp (Lit (Int i)) op (Lit (Int j)))
            | op ~= "-" = Lit $ Int $ i - j
            | op ~= ">" = Con $ UnQual $ Ident $ show $ i > j
        fExp (InfixApp x op y) | op ~= "`const`" = x
        fExp (App (App con x) y) | con ~= "const" = x
        fExp (Paren (Var x)) = Var x
        fExp (Paren (Lit x)) = Lit x
        fExp x = x
\end{code}

\subsection{DSL Usage}

What can we do with DSLs? The world is our Oyster, we can generate |Data| based reflective code, we can generate concrete instances, we can write out an instance generator.

Currently an instance is a fragment of compile time code, but using Haskell's reflection capabilities \cite{lammel:syb2}, instances could be derived at run-time, removing the inconvenience of a separate preprocessor.

\section{Results}
\label{sec:results}

\subsection{Limitations of Automatic Derivation}
\label{sec:failure}

The instance generation scheme given is not complete -- there exist instances whose generator cannot be determined. The Derive tool \cite{derive} is a program for generating instances for user defined data types. Of the 24 instances supported by the Derive tool, 15 are expressed by example, while 9 require manually written instance generators. There are several reasons some instances cannot be determined:

\begin{description}

\item[Non-inductive definitions:] For example, the |Binary| class serialises a value to disk. For each value, a tag is written to indicate the constructor. If a data type has only one constructor, the tag is omitted. These instances are not inductive -- the single constructor does not follow the same pattern.

\item[Type-based definitions:] For example, the |Monoid| class requires items of the same type to be processed using |mappend|, but items of a different type use |mempty|. Automatic derivation has no notion of type-specific behaviour.

\item [Record-based definitions:] Haskell provides records, which allow fields to be labelled. The |Show| class outputs the field name if present, but the examples have no notion of label-specific behaviour. By extending |Sample|, record definitions could be determined, but this change would increase the complexity of all other example instances.

\end{description}

\subsection{Generation of Standard Classes}
\label{sec:automatic_success}

Many instance generators can be expressed by example -- including some from the standard Haskell libraries (|Enum|, |Ord|, |Bounded|) and publicly distributed libraries (|Serial|, |Arbitrary|). The |Data| class was introduced in Scrap Your Boilerplate \cite{lammel:syb}, and allows Haskell programmers to write concise queries and transformations. The fundamental operation is |gfoldl|, which involves a fold over each value, and the application of an argument to join the fields. An example instance can be given as:

\begin{code}
instance Data alpha => Data (Sample alpha) where
    gfoldl k r (First            ) = r First
    gfoldl k r (Second  x_1 x_2  ) = r Second  `k` x_1 `k` x_2
    gfoldl k r (Third   x_1      ) = r Third   `k` x_1
\end{code}

\noindent The generator function is inferred as:

\ignore\begin{code}
instance Data \? <| dataname |> where
    <| MAP ctors (
        gfoldl k r
            (<| ctorname |> \? <| MAP [1..ctorarity] (x <| # |> ) |> ) =
            <| FOLDR k (r \? <| ctorname |>)
                <| MAP [1 .. ctorarity] (x <| # |> ) |>
            |>
    ) |>
\end{code}

\subsection{Tricks for Increasing Power}

Take a look at Binary, which writes out tags in clever ways.

\subsection{Timing Properties}

Inference time to write the derivations for everything to a file is under a tenth of a second. To write the data to the screen takes 3 tenths of a second. We conclude that guesses aren't too slow!

\subsection{Extensions}

How would we increase it to get more power.

Record names could be added. The difficulty here is that record names can be shared between constructors, in different orders, some constructors may not have record names etc. For a system such as F#, where only one constructor is allowed and all fields must be named, this may be more feasible.

Another property is types. The problem here is that types are two numerous, and while extensions could provide one or two -- for example |Functor|, they won't be able to do a huge number.

\section{Related Work}
\label{sec:related}

The purpose of this work is to find a pattern, and generalise that pattern to other situations. Genetic algorithms \cite{genetic_algorithms} are often used to automatically find a pattern in a data set. Genetic algorithms work by evolving a hypothesis (a gene sequence) and testing on a sample problem. They are well suited to search problems where the utility function is continuous -- close hypotheses have similar fitness. The main difference from this paper is that the hypothesis is random, whereas ours is strongly directed by the shape of the example.

The area of optical character recognition \cite{ocr} has some similar characteristics -- a page is analysed to look for common patterns (pictures or text passages), which can be processed further. This is related to the process of using the fold pattern (\S\ref{sec:fold}), where a repeating pattern is detected. The difference is that character recognition works on image data, which does not have the same precision as program code.

The closest work we are aware of is that of the theorem proving community. Induction is a very common tactic for writing proofs, and well supported in systems such as HOL Light \cite{hol_light}. Typically the user must suggest the use of induction, which the system checks for validity. Automatic inference of an induction argument has been tried \cite{mintchev:reasoning}, but is rarely successful.

The concepts in this paper are applicable outside the domain of instances in Haskell. Any programming language operation that exhibits some degree of uniformity could be automated. To give one example: the object-orientated community have embraced design patterns \cite{design_patterns}, which involve many recurring patterns.

\section{Conclusions and Future Work}
\label{sec:conclusion}

We have presented a mechanism for automatically deriving instance generators for Haskell type classes. Our technique has been implemented in the Derive tool \cite{derive}, where 60\% of instance generators are specified by example. The ease of creating new instances has enabled several users to contribute instance generators to the Derive tool. We see several lines of future work:

\begin{itemize}
\item Using automatic instance generation allows the underlying tool to change the API for specifying instances, without requiring human intervention to modify the generators -- they can simply be regenerated. This freedom allows instances to be expressed in new ways.
\item The provided data type (Figure \ref{fig:sample}) allows many instances to be inferred -- but more would be desirable. One approach to specifying more instances would be to augment the existing data type with additional features, such as record names (see \S\ref{sec:automatic_failure}). An alternative approach would be to introduce new data types with features specifically targeted for certain types of definition. Care would have to be taken to ensure that these extensions do not substantially increase the complexity of writing examples.
\item We could make everything more type safe using GADT's.
\end{itemize}

Computers are ideally suited to applying repetitive patterns, but specifying these patterns can be complex and error prone. By specifying the result, instead of the pattern, a user can focus on what they want, rather than the mechanism by which this is realized.

\subsection*{Acknowledgements}

Thanks to Stefan O'Rear help with the first version of the \derive{} tool.


\bibliographystyle{plainnat}
\bibliography

\appendix
\section{The |apply| function}

\begin{code}
apply = -- \todo{insert apply here}
\end{code}

\end{document}
